Search.setIndex({"docnames": ["index", "modules", "src", "src.classification", "src.classification.image", "src.classification.speech", "src.classification.text", "src.data", "src.evaluation", "src.experiment"], "filenames": ["index.rst", "modules.rst", "src.rst", "src.classification.rst", "src.classification.image.rst", "src.classification.speech.rst", "src.classification.text.rst", "src.data.rst", "src.evaluation.rst", "src.experiment.rst"], "titles": ["Documentation of the multimodal emotion measurement system", "emotion-recognition", "src package", "src.classification package", "src.classification.image package", "src.classification.speech package", "src.classification.text package", "src.data package", "src.evaluation package", "src.experiment package"], "terms": {"recognit": 0, "src": [0, 1], "packag": [0, 1], "index": [0, 2, 6], "modul": [0, 1], "search": 0, "page": 0, "subpackag": 1, "classif": [1, 2], "submodul": 1, "classifier_factori": [1, 2], "emotion_classifi": [1, 2], "content": 1, "data": [1, 2, 4, 6, 8], "balanced_image_data_read": [1, 2], "classwise_speech_data_read": [1, 2], "data_factori": [1, 2], "data_read": [1, 2], "image_data_read": [1, 2], "speech_data_read": [1, 2], "text_data_read": [1, 2], "evalu": [1, 2, 7], "experi": [1, 2, 8], "emotion_set": 1, "imag": [2, 3, 7], "cross_attention_classifi": [2, 3], "efficientnet_classifi": [2, 3], "image_emotion_classifi": [2, 3], "vgg16_classifi": [2, 3], "speech": [2, 3, 7], "byols_classifi": [2, 3], "gmm_classifi": [2, 3], "hmm_classifi": [2, 3], "hubert_classifi": [2, 3], "mfcc_lstm_classifi": [2, 3], "speech_emotion_classifi": [2, 3], "svm_classifi": [2, 3], "wav2vec2_classifi": [2, 3], "text": [2, 3, 7], "bert_classifi": [2, 3], "distilbert_classifi": [2, 3], "nrclex_classifi": [2, 3], "text_emotion_classifi": [2, 3], "thi": [2, 3, 4, 6, 7, 8], "file": [2, 4, 7, 8], "defin": [2, 7], "emot": [2, 3, 4, 6, 7], "set": [2, 3, 7], "ar": [2, 3, 6, 7], "avail": [2, 7], "work": 2, "class": [2, 3, 4, 6, 7, 8], "abstractemotionset": 2, "name": [2, 3, 4, 6, 7], "str": [2, 3, 4, 6, 7, 8], "count": [2, 3], "int": [2, 3, 4, 6, 7], "iter": [2, 8], "base": [2, 3, 4, 6, 7, 8], "object": [2, 7, 8], "implement": [2, 3, 4, 6, 7, 8], "abstract": [2, 3, 4, 6, 7], "interfac": [2, 3, 4, 6], "all": [2, 3, 4, 6, 7, 8], "One": 2, "problem": 2, "detect": [2, 7], "i": [2, 3, 4, 6, 7, 8], "lot": 2, "differ": [2, 7, 8], "us": [2, 3, 4, 6, 7, 8], "throughout": 2, "past": 2, "research": 2, "while": [2, 4], "one": [2, 7, 8], "paper": [2, 4], "predict": [2, 3, 4, 6], "onli": [2, 6, 7], "posit": 2, "neutral": 2, "neg": 2, "anoth": 2, "might": [2, 7], "differenti": 2, "between": 2, "6": [2, 7], "more": [2, 4], "distinct": 2, "joi": 2, "anger": 2, "fear": 2, "model": [2, 3, 4, 6, 7], "behaviour": 2, "get_emot": 2, "indic": [2, 3, 4, 6], "union": [2, 8], "ndarrai": [2, 7], "function": [2, 3, 4, 6, 7, 8], "return": [2, 3, 4, 6, 7, 8], "string": [2, 8], "given": [2, 3, 7], "paramet": [2, 3, 4, 6, 7, 8], "The": [2, 3, 4, 6, 7], "arrai": [2, 3, 4, 6, 7], "singl": [2, 7, 8], "ekmanemot": 2, "paul": 2, "ekman": 2, "commonli": 2, "It": [2, 6], "contain": [2, 4, 6, 7, 8], "basic": [2, 7, 8], "surpris": 2, "disgust": 2, "enjoy": 2, "sad": 2, "ekmanneutralemot": 2, "extend": 2, "state": 2, "emotionmapp": 2, "map_emot": [2, 7], "map": [2, 4, 7], "an": [2, 3, 4, 6, 7, 8], "its": 2, "equival": 2, "neutralekman": [2, 7], "correspond": 2, "setup_map": 2, "none": [2, 3, 4, 6, 7, 8], "time": [2, 7], "setup": 2, "emotionsetfactori": 2, "factori": [2, 7], "gener": [2, 6, 7], "instanc": [2, 7], "static": [2, 3, 7], "method": [2, 3, 4, 6, 7], "creat": [2, 7], "specifi": [2, 7], "desir": 2, "rais": [2, 7], "valueerror": [2, 7], "doe": [2, 6, 7], "repres": [2, 8], "threeemot": [2, 7], "simpl": 2, "three": [2, 4, 7], "categori": 2, "entir": [2, 7], "sourc": 2, "code": [2, 8], "classifi": [3, 4, 6, 7, 8], "emotionclassifi": [3, 4, 6], "data_typ": [3, 7], "option": [3, 4, 6, 7], "dict": [3, 4, 6, 7, 8], "abc": [3, 7], "kwarg": [3, 4, 6, 8], "virtual": [3, 4, 6], "dictionari": [3, 4, 6, 7], "addit": [3, 4, 6, 7, 8], "get_class_weight": 3, "which_set": [3, 4, 6, 7], "weight": [3, 4], "dataset": [3, 4, 6, 7], "": 3, "kei": 3, "label": [3, 4, 7], "valu": [3, 4, 7], "which": [3, 4, 6, 7], "calcul": 3, "init_paramet": 3, "merg": 3, "combin": 3, "load": [3, 4, 6, 7], "previous": [3, 4, 6], "train": [3, 4, 6, 7, 8], "from": [3, 4, 6, 7, 8], "disk": [3, 4, 6, 7], "requir": [3, 4, 6, 7], "save": [3, 4, 6], "store": [3, 4, 6, 7], "respons": [3, 7], "crossattent": 4, "facial": 4, "affinityloss": 4, "devic": 4, "num_class": 4, "7": [4, 7], "feat_dim": 4, "512": 4, "affin": 4, "loss": 4, "suppos": 4, "increas": 4, "inter": 4, "distanc": 4, "decreas": 4, "intra": 4, "For": 4, "detail": 4, "about": 4, "comput": [4, 8], "go": 4, "chapter": 4, "3": [4, 7], "1": [4, 7], "forward": 4, "x": [4, 7], "tensor": [4, 7], "pass": 4, "through": 4, "featur": 4, "dan": 4, "output": 4, "after": 4, "resnet": 4, "input": 4, "bool": [4, 7], "channelattent": 4, "layer": 4, "second": 4, "part": 4, "crossattentionhead": 4, "sa": 4, "should": [4, 7], "spatialattent": 4, "head": 4, "pytorch": 4, "taken": 4, "origin": 4, "without": 4, "chang": 4, "attentionhead": 4, "init_weight": 4, "initi": [4, 6], "crossattentionnetworkclassifi": 4, "imageemotionclassifi": 4, "multi": 4, "cross": 4, "attent": 4, "network": 4, "resnet50": 4, "can": [4, 6, 7, 8], "found": 4, "here": [4, 7], "http": [4, 7], "paperswithcod": 4, "com": [4, 7], "distract": 4, "your": 4, "initialize_model": 4, "new": 4, "pretrain": 4, "version": 4, "github": [4, 7], "yao": 4, "adapt": 4, "slightli": 4, "transform_data": 4, "tupl": [4, 7], "transform": 4, "torch": 4, "correct": 4, "format": [4, 7], "batch": [4, 6, 7], "num_head": 4, "4": 4, "true": [4, 7], "wa": [4, 7], "introduc": 4, "element": 4, "0": [4, 7], "2": [4, 7], "befor": 4, "partitionloss": 4, "partit": 4, "maxim": 4, "varianc": 4, "among": 4, "refer": 4, "efficientnet": 4, "multitaskefficientnetb2classifi": 4, "effici": 4, "net": 4, "efficientnetb2": 4, "common": [4, 6], "concern": [4, 6], "prepare_data": 4, "prepar": 4, "them": [4, 7, 8], "insid": 4, "import": 4, "param": [4, 7, 8], "includ": 4, "batch_siz": [4, 6, 7], "prepare_train": 4, "optim": 4, "metric": 4, "callback": 4, "vgg16": 4, "vgg16classifi": 4, "bert": 6, "bertclassifi": 6, "textemotionclassifi": 6, "size": [6, 7], "Not": 6, "current": 6, "save_path": 6, "folder": [6, 7], "where": [6, 7], "init_lr": 6, "learn": 6, "rate": 6, "epoch": 6, "number": 6, "distilbert": 6, "distilbertclassifi": 6, "we": 6, "reus": 6, "nrclex": 6, "python": 6, "librari": 6, "nrclextextclassifi": 6, "lexicon": 6, "find": 6, "word": 6, "make": 6, "mean": [6, 7], "necessari": 6, "loader": 6, "result": [6, 7, 8], "shape": [6, 7], "num_sampl": [6, 7], "get_best_emot": 6, "raw_scor": 6, "get": [6, 7], "score": [6, 8], "most": 6, "like": [6, 7], "raw": 6, "integ": [6, 7], "neutral_ekman": [6, 7], "space": [6, 7], "storag": 6, "reader": 7, "balanc": 7, "balancedimagedataread": 7, "imagedataread": 7, "read": [7, 8], "wai": 7, "approxim": 7, "equal": 7, "amount": 7, "some": 7, "underrepres": 7, "appear": 7, "twice": 7, "overrepres": 7, "note": 7, "ha": 7, "higher": 7, "memori": 7, "than": 7, "other": 7, "get_label": 7, "val": 7, "test": 7, "get_seven_emotion_data": 7, "64": 7, "datasetv2": 7, "main": [7, 8], "csv": 7, "also": 7, "convert": 7, "argument": [7, 8], "tensorflow": 7, "get_three_emotion_data": 7, "classwis": 7, "classwisespeechdataread": 7, "classwise_speech": 7, "dataread": 7, "per": 7, "extract": 7, "hmm": 7, "gmm": 7, "need": 7, "same": 7, "do": 7, "support": 7, "nn": 7, "get_crema_sampl": 7, "crema_d": 7, "class_nam": 7, "sampl": 7, "crema": 7, "A": [7, 8], "numpi": 7, "get_file_sampl": 7, "emotion_class": 7, "data_dir": 7, "specif": 7, "directori": 7, "audio": 7, "yield": 7, "get_waveform_and_label": 7, "file_path": 7, "byte": 7, "preprocess": 7, "decod": 7, "pad": 7, "truncat": 7, "path": [7, 8], "convers": 7, "appli": 7, "when": 7, "process_crema": 7, "y": 7, "tensorflow_dataset": 7, "process": 7, "easi": 7, "access": 7, "datafactori": 7, "get_data_read": 7, "data_fold": 7, "type": 7, "overrid": 7, "If": 7, "exist": 7, "get_dataset": 7, "consid": 7, "request": 7, "convert_to_numpi": 7, "two": 7, "convert_to_three_emot": 7, "neutralekmanemot": 7, "threeemotionset": 7, "convert_to_three_emotions_onehot": 7, "hot": 7, "encod": 7, "n": 7, "get_emotion_data": 7, "depend": 7, "obtain": 7, "either": 7, "instead": 7, "neutralekmanemotionset": 7, "distinguish": 7, "enum": 7, "add_augment": 7, "use_augment": 7, "add": 7, "augment": 7, "help": 7, "reduc": 7, "overfit": 7, "boolean": 7, "flag": 7, "enabl": 7, "speechdataread": 7, "set_tensor_shap": 7, "manual": 7, "fix": 7, "issu": 7, "numpy_funct": 7, "caus": 7, "unknown": 7, "see": 7, "47032": 7, "textdataread": 7, "unus": 7, "get_paramet": 8, "list": 8, "get_scor": 8, "float": 8, "keyword": 8, "read_result": 8, "thing": 8, "glob": 8, "must": 8, "least": 8, "e": 8, "g": 8, "compar": 8}, "objects": {"": [[2, 0, 0, "-", "src"]], "src": [[3, 0, 0, "-", "classification"], [7, 0, 0, "-", "data"], [2, 0, 0, "-", "emotion_set"], [8, 0, 0, "-", "evaluation"], [9, 0, 0, "-", "experiment"]], "src.classification": [[3, 0, 0, "-", "emotion_classifier"], [4, 0, 0, "-", "image"], [6, 0, 0, "-", "text"]], "src.classification.emotion_classifier": [[3, 1, 1, "", "EmotionClassifier"]], "src.classification.emotion_classifier.EmotionClassifier": [[3, 2, 1, "", "classify"], [3, 2, 1, "", "get_class_weights"], [3, 2, 1, "", "init_parameters"], [3, 2, 1, "", "load"], [3, 2, 1, "", "save"], [3, 2, 1, "", "train"]], "src.classification.image": [[4, 0, 0, "-", "cross_attention_classifier"], [4, 0, 0, "-", "efficientnet_classifier"], [4, 0, 0, "-", "image_emotion_classifier"], [4, 0, 0, "-", "vgg16_classifier"]], "src.classification.image.cross_attention_classifier": [[4, 1, 1, "", "AffinityLoss"], [4, 1, 1, "", "ChannelAttention"], [4, 1, 1, "", "CrossAttentionHead"], [4, 1, 1, "", "CrossAttentionNetworkClassifier"], [4, 1, 1, "", "DAN"], [4, 1, 1, "", "PartitionLoss"], [4, 1, 1, "", "SpatialAttention"]], "src.classification.image.cross_attention_classifier.AffinityLoss": [[4, 2, 1, "", "forward"], [4, 3, 1, "", "training"]], "src.classification.image.cross_attention_classifier.ChannelAttention": [[4, 2, 1, "", "forward"], [4, 3, 1, "", "training"]], "src.classification.image.cross_attention_classifier.CrossAttentionHead": [[4, 2, 1, "", "forward"], [4, 2, 1, "", "init_weights"], [4, 3, 1, "", "training"]], "src.classification.image.cross_attention_classifier.CrossAttentionNetworkClassifier": [[4, 2, 1, "", "classify"], [4, 2, 1, "", "initialize_model"], [4, 2, 1, "", "load"], [4, 2, 1, "", "save"], [4, 2, 1, "", "train"], [4, 2, 1, "", "transform_data"]], "src.classification.image.cross_attention_classifier.DAN": [[4, 2, 1, "", "forward"], [4, 3, 1, "", "training"]], "src.classification.image.cross_attention_classifier.PartitionLoss": [[4, 2, 1, "", "forward"], [4, 3, 1, "", "training"]], "src.classification.image.cross_attention_classifier.SpatialAttention": [[4, 2, 1, "", "forward"], [4, 3, 1, "", "training"]], "src.classification.image.efficientnet_classifier": [[4, 1, 1, "", "MultiTaskEfficientNetB2Classifier"]], "src.classification.image.efficientnet_classifier.MultiTaskEfficientNetB2Classifier": [[4, 2, 1, "", "classify"], [4, 2, 1, "", "initialize_model"], [4, 2, 1, "", "load"], [4, 2, 1, "", "save"], [4, 2, 1, "", "train"]], "src.classification.image.image_emotion_classifier": [[4, 1, 1, "", "ImageEmotionClassifier"]], "src.classification.image.image_emotion_classifier.ImageEmotionClassifier": [[4, 2, 1, "", "classify"], [4, 2, 1, "", "load"], [4, 2, 1, "", "prepare_data"], [4, 2, 1, "", "prepare_training"], [4, 2, 1, "", "save"], [4, 2, 1, "", "train"]], "src.classification.image.vgg16_classifier": [[4, 1, 1, "", "VGG16Classifier"]], "src.classification.image.vgg16_classifier.VGG16Classifier": [[4, 2, 1, "", "classify"], [4, 2, 1, "", "initialize_model"], [4, 2, 1, "", "load"], [4, 2, 1, "", "save"], [4, 2, 1, "", "train"]], "src.classification.text": [[6, 0, 0, "-", "bert_classifier"], [6, 0, 0, "-", "distilbert_classifier"], [6, 0, 0, "-", "nrclex_classifier"], [6, 0, 0, "-", "text_emotion_classifier"]], "src.classification.text.bert_classifier": [[6, 1, 1, "", "BertClassifier"]], "src.classification.text.bert_classifier.BertClassifier": [[6, 2, 1, "", "classify"], [6, 2, 1, "", "load"], [6, 2, 1, "", "save"], [6, 2, 1, "", "train"]], "src.classification.text.distilbert_classifier": [[6, 1, 1, "", "DistilBertClassifier"]], "src.classification.text.distilbert_classifier.DistilBertClassifier": [[6, 2, 1, "", "load"], [6, 2, 1, "", "save"]], "src.classification.text.nrclex_classifier": [[6, 1, 1, "", "NRCLexTextClassifier"]], "src.classification.text.nrclex_classifier.NRCLexTextClassifier": [[6, 2, 1, "", "classify"], [6, 2, 1, "", "get_best_emotion"], [6, 2, 1, "", "load"], [6, 2, 1, "", "save"], [6, 2, 1, "", "train"]], "src.classification.text.text_emotion_classifier": [[6, 1, 1, "", "TextEmotionClassifier"]], "src.classification.text.text_emotion_classifier.TextEmotionClassifier": [[6, 2, 1, "", "classify"], [6, 2, 1, "", "load"], [6, 2, 1, "", "save"], [6, 2, 1, "", "train"]], "src.data": [[7, 0, 0, "-", "balanced_image_data_reader"], [7, 0, 0, "-", "classwise_speech_data_reader"], [7, 0, 0, "-", "data_factory"], [7, 0, 0, "-", "data_reader"], [7, 0, 0, "-", "image_data_reader"], [7, 0, 0, "-", "speech_data_reader"], [7, 0, 0, "-", "text_data_reader"]], "src.data.balanced_image_data_reader": [[7, 1, 1, "", "BalancedImageDataReader"]], "src.data.balanced_image_data_reader.BalancedImageDataReader": [[7, 2, 1, "", "get_labels"], [7, 2, 1, "", "get_seven_emotion_data"], [7, 2, 1, "", "get_three_emotion_data"]], "src.data.classwise_speech_data_reader": [[7, 1, 1, "", "ClasswiseSpeechDataReader"]], "src.data.classwise_speech_data_reader.ClasswiseSpeechDataReader": [[7, 2, 1, "", "get_crema_samples"], [7, 2, 1, "", "get_file_samples"], [7, 2, 1, "", "get_labels"], [7, 2, 1, "", "get_seven_emotion_data"], [7, 2, 1, "", "get_three_emotion_data"], [7, 2, 1, "", "get_waveform_and_label"], [7, 2, 1, "", "map_emotions"], [7, 2, 1, "", "process_crema"]], "src.data.data_factory": [[7, 1, 1, "", "DataFactory"]], "src.data.data_factory.DataFactory": [[7, 2, 1, "", "get_data_reader"], [7, 2, 1, "", "get_dataset"]], "src.data.data_reader": [[7, 1, 1, "", "DataReader"], [7, 1, 1, "", "Set"]], "src.data.data_reader.DataReader": [[7, 2, 1, "", "convert_to_numpy"], [7, 2, 1, "", "convert_to_three_emotions"], [7, 2, 1, "", "convert_to_three_emotions_onehot"], [7, 2, 1, "", "get_emotion_data"], [7, 2, 1, "", "get_labels"], [7, 2, 1, "", "get_seven_emotion_data"], [7, 2, 1, "", "get_three_emotion_data"]], "src.data.data_reader.Set": [[7, 3, 1, "", "TEST"], [7, 3, 1, "", "TRAIN"], [7, 3, 1, "", "VAL"]], "src.data.image_data_reader": [[7, 1, 1, "", "ImageDataReader"]], "src.data.image_data_reader.ImageDataReader": [[7, 2, 1, "", "add_augmentations"], [7, 2, 1, "", "get_labels"], [7, 2, 1, "", "get_seven_emotion_data"], [7, 2, 1, "", "get_three_emotion_data"], [7, 2, 1, "", "map_emotions"]], "src.data.speech_data_reader": [[7, 1, 1, "", "SpeechDataReader"]], "src.data.speech_data_reader.SpeechDataReader": [[7, 2, 1, "", "get_labels"], [7, 2, 1, "", "get_seven_emotion_data"], [7, 2, 1, "", "get_three_emotion_data"], [7, 2, 1, "", "get_waveform_and_label"], [7, 2, 1, "", "map_emotions"], [7, 2, 1, "", "process_crema"], [7, 2, 1, "", "set_tensor_shapes"]], "src.data.text_data_reader": [[7, 1, 1, "", "TextDataReader"]], "src.data.text_data_reader.TextDataReader": [[7, 2, 1, "", "get_labels"], [7, 2, 1, "", "get_seven_emotion_data"], [7, 2, 1, "", "get_three_emotion_data"]], "src.emotion_set": [[2, 1, 1, "", "AbstractEmotionSet"], [2, 1, 1, "", "EkmanEmotions"], [2, 1, 1, "", "EkmanNeutralEmotions"], [2, 1, 1, "", "EmotionMapper"], [2, 1, 1, "", "EmotionSetFactory"], [2, 1, 1, "", "ThreeEmotions"]], "src.emotion_set.AbstractEmotionSet": [[2, 2, 1, "", "get_emotions"]], "src.emotion_set.EmotionMapper": [[2, 2, 1, "", "map_emotion"], [2, 2, 1, "", "setup_map"]], "src.emotion_set.EmotionSetFactory": [[2, 2, 1, "", "generate"]], "src.evaluation": [[8, 0, 0, "-", "evaluator"]], "src.evaluation.evaluator": [[8, 1, 1, "", "Evaluator"]], "src.evaluation.evaluator.Evaluator": [[8, 2, 1, "", "get_parameters"], [8, 2, 1, "", "get_scores"], [8, 2, 1, "", "read_results"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"]}, "titleterms": {"document": 0, "multimod": 0, "emot": [0, 1], "measur": 0, "system": 0, "content": [0, 2, 3, 4, 5, 6, 7, 8, 9], "indic": 0, "tabl": 0, "recognit": 1, "src": [2, 3, 4, 5, 6, 7, 8, 9], "packag": [2, 3, 4, 5, 6, 7, 8, 9], "subpackag": [2, 3], "submodul": [2, 3, 4, 5, 6, 7, 8, 9], "emotion_set": 2, "modul": [2, 3, 4, 5, 6, 7, 8, 9], "classif": [3, 4, 5, 6], "classifier_factori": 3, "emotion_classifi": 3, "imag": 4, "cross_attention_classifi": 4, "efficientnet_classifi": 4, "image_emotion_classifi": 4, "vgg16_classifi": 4, "speech": 5, "byols_classifi": 5, "gmm_classifi": 5, "hmm_classifi": 5, "hubert_classifi": 5, "mfcc_lstm_classifi": 5, "speech_emotion_classifi": 5, "svm_classifi": 5, "wav2vec2_classifi": 5, "text": 6, "bert_classifi": 6, "distilbert_classifi": 6, "nrclex_classifi": 6, "text_emotion_classifi": 6, "data": 7, "balanced_image_data_read": 7, "classwise_speech_data_read": 7, "data_factori": 7, "data_read": 7, "image_data_read": 7, "speech_data_read": 7, "text_data_read": 7, "evalu": 8, "experi": 9}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 56}})